[root@INBACRNRDL0102 ~]# oc logs must-gather-rpxln
Defaulted container "gather" out of: gather, copy
Gathering data for ns/openshift-cluster-version...
Gathering data for ns/openshift-cluster-version...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Gathering data for ns/default...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Waiting on subprocesses to finish execution.
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Gathering HAProxy config files
Waiting on subprocesses to finish execution.
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Gathering HAProxy config files
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Waiting for node performance related collection to complete ...
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Waiting for node performance related collection to complete ...
Gathering data for ns/default...
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "metallb-operator" not detected. Skipping.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
Wrote inspect data to must-gather.
No resources found
No resources found
INFO: "metallb-operator" not detected. Skipping.
Wrote inspect data to must-gather.
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "sriov-network-operator" not detected. Skipping.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
INFO: "sriov-network-operator" not detected. Skipping.
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
INFO: Waiting for HAProxy config collection to complete ...
Gathering data for ns/openshift...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
Wrote inspect data to must-gather.
No resources found
Wrote inspect data to must-gather.
No resources found
INFO: Waiting for HAProxy config collection to complete ...
W0215 23:03:09.312414    2104 util.go:195] skipping , failed to read event err: Object 'Kind' is missing in ''
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
tar: Removing leading `/' from member names
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
Wrote inspect data to must-gather.
receiving incremental file list
insights-operator/
insights-operator/insights-2025-02-15-214440.tar.gz

sent 47 bytes  received 378,667 bytes  757,428.00 bytes/sec
total size is 378,419  speedup is 1.00
error: the server doesn't have a resource type "multi-networkpolicy"
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
error: the server doesn't have a resource type "multi-networkpolicy"
Wrote inspect data to must-gather.
Gathering data for ns/openshift...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
receiving incremental file list
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host

sent 25 bytes  received 114 bytes  278.00 bytes/sec
total size is 378,419  speedup is 2,722.44
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
Wrote inspect data to must-gather.
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Gathering data for ns/kube-system...
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/kube-system...
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
Gathering data for ns/openshift-config-managed...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Gathering data for ns/openshift-config-managed...
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Error from server (AlreadyExists): error when creating "STDIN": daemonsets.apps "perf-node-gather-daemonset" already exists
daemonset.apps/perf-node-gather-daemonset created
Gathering data for ns/openshift-authentication...
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
Waiting for performance profile collector pods to become ready: 1
Waiting for performance profile collector pods to become ready: 1
Gathering data for ns/openshift-authentication...
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Waiting for performance profile collector pods to become ready: 2
Waiting for performance profile collector pods to become ready: 2
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 4
Waiting for performance profile collector pods to become ready: 4
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
14M	must-gather/network_logs/ovnk_database_store
ovnk_database_store/
ovnk_database_store/ovnkube-node-v96dr_nbdb
ovnk_database_store/ovnkube-node-v96dr_sbdb
ovnk_database_store/ovnkube-node-pk6hx_nbdb
ovnk_database_store/ovnkube-node-pk6hx_sbdb
INFO: Network log collection complete.
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 7
Waiting for performance profile collector pods to become ready: 7
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
du: cannot access 'must-gather/network_logs/ovnk_database_store': No such file or directory
tar: ovnk_database_store: Cannot stat: No such file or directory
tar: Exiting with failure status due to previous errors
INFO: Network log collection complete.
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 8
Waiting for performance profile collector pods to become ready: 8
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 9
Waiting for performance profile collector pods to become ready: 9
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 10
Waiting for performance profile collector pods to become ready: 10
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 12
Waiting for performance profile collector pods to become ready: 12
rm: cannot remove '../must-gather/monitoring/ca-bundle.crt': No such file or directory
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 24
Waiting for performance profile collector pods to become ready: 24
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 26
Waiting for performance profile collector pods to become ready: 26
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 30
Waiting for performance profile collector pods to become ready: 30
[root@INBACRNRDL0102 ~]# oc logs must-gather-rpxln
Defaulted container "gather" out of: gather, copy
Gathering data for ns/openshift-cluster-version...
Gathering data for ns/openshift-cluster-version...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Gathering data for ns/default...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Waiting on subprocesses to finish execution.
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Gathering HAProxy config files
Waiting on subprocesses to finish execution.
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Gathering HAProxy config files
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Waiting for node performance related collection to complete ...
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Waiting for node performance related collection to complete ...
Gathering data for ns/default...
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "metallb-operator" not detected. Skipping.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
Wrote inspect data to must-gather.
No resources found
No resources found
INFO: "metallb-operator" not detected. Skipping.
Wrote inspect data to must-gather.
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "sriov-network-operator" not detected. Skipping.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
INFO: "sriov-network-operator" not detected. Skipping.
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
INFO: Waiting for HAProxy config collection to complete ...
Gathering data for ns/openshift...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
Wrote inspect data to must-gather.
No resources found
Wrote inspect data to must-gather.
No resources found
INFO: Waiting for HAProxy config collection to complete ...
W0215 23:03:09.312414    2104 util.go:195] skipping , failed to read event err: Object 'Kind' is missing in ''
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
tar: Removing leading `/' from member names
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
Wrote inspect data to must-gather.
receiving incremental file list
insights-operator/
insights-operator/insights-2025-02-15-214440.tar.gz

sent 47 bytes  received 378,667 bytes  757,428.00 bytes/sec
total size is 378,419  speedup is 1.00
error: the server doesn't have a resource type "multi-networkpolicy"
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
error: the server doesn't have a resource type "multi-networkpolicy"
Wrote inspect data to must-gather.
Gathering data for ns/openshift...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
receiving incremental file list
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host

sent 25 bytes  received 114 bytes  278.00 bytes/sec
total size is 378,419  speedup is 2,722.44
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
Wrote inspect data to must-gather.
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Gathering data for ns/kube-system...
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/kube-system...
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
Gathering data for ns/openshift-config-managed...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Gathering data for ns/openshift-config-managed...
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Error from server (AlreadyExists): error when creating "STDIN": daemonsets.apps "perf-node-gather-daemonset" already exists
daemonset.apps/perf-node-gather-daemonset created
Gathering data for ns/openshift-authentication...
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
Waiting for performance profile collector pods to become ready: 1
Waiting for performance profile collector pods to become ready: 1
Gathering data for ns/openshift-authentication...
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Waiting for performance profile collector pods to become ready: 2
Waiting for performance profile collector pods to become ready: 2
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 4
Waiting for performance profile collector pods to become ready: 4
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
14M	must-gather/network_logs/ovnk_database_store
ovnk_database_store/
ovnk_database_store/ovnkube-node-v96dr_nbdb
ovnk_database_store/ovnkube-node-v96dr_sbdb
ovnk_database_store/ovnkube-node-pk6hx_nbdb
ovnk_database_store/ovnkube-node-pk6hx_sbdb
INFO: Network log collection complete.
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 7
Waiting for performance profile collector pods to become ready: 7
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
du: cannot access 'must-gather/network_logs/ovnk_database_store': No such file or directory
tar: ovnk_database_store: Cannot stat: No such file or directory
tar: Exiting with failure status due to previous errors
INFO: Network log collection complete.
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 8
Waiting for performance profile collector pods to become ready: 8
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 9
Waiting for performance profile collector pods to become ready: 9
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 10
Waiting for performance profile collector pods to become ready: 10
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 12
Waiting for performance profile collector pods to become ready: 12
rm: cannot remove '../must-gather/monitoring/ca-bundle.crt': No such file or directory
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 24
Waiting for performance profile collector pods to become ready: 24
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 26
Waiting for performance profile collector pods to become ready: 26
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 30
Waiting for performance profile collector pods to become ready: 30
Waiting for performance profile collector pods to become ready: 31
Waiting for performance profile collector pods to become ready: 31
Waiting for performance profile collector pods to become ready: 32
Waiting for performance profile collector pods to become ready: 32
Waiting for performance profile collector pods to become ready: 33
Waiting for performance profile collector pods to become ready: 33
Gathering data for ns/openshift-cloud-controller-manager-operator...
Gathering data for ns/openshift-cloud-controller-manager...
[root@INBACRNRDL0102 ~]# oc logs must-gather-rpxln
Defaulted container "gather" out of: gather, copy
Gathering data for ns/openshift-cluster-version...
Gathering data for ns/openshift-cluster-version...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Gathering data for ns/default...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Waiting on subprocesses to finish execution.
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Gathering HAProxy config files
Waiting on subprocesses to finish execution.
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Gathering HAProxy config files
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Waiting for node performance related collection to complete ...
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Waiting for node performance related collection to complete ...
Gathering data for ns/default...
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "metallb-operator" not detected. Skipping.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
Wrote inspect data to must-gather.
No resources found
No resources found
INFO: "metallb-operator" not detected. Skipping.
Wrote inspect data to must-gather.
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "sriov-network-operator" not detected. Skipping.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
INFO: "sriov-network-operator" not detected. Skipping.
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
INFO: Waiting for HAProxy config collection to complete ...
Gathering data for ns/openshift...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
Wrote inspect data to must-gather.
No resources found
Wrote inspect data to must-gather.
No resources found
INFO: Waiting for HAProxy config collection to complete ...
W0215 23:03:09.312414    2104 util.go:195] skipping , failed to read event err: Object 'Kind' is missing in ''
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
tar: Removing leading `/' from member names
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
Wrote inspect data to must-gather.
receiving incremental file list
insights-operator/
insights-operator/insights-2025-02-15-214440.tar.gz

sent 47 bytes  received 378,667 bytes  757,428.00 bytes/sec
total size is 378,419  speedup is 1.00
error: the server doesn't have a resource type "multi-networkpolicy"
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
error: the server doesn't have a resource type "multi-networkpolicy"
Wrote inspect data to must-gather.
Gathering data for ns/openshift...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
receiving incremental file list
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host

sent 25 bytes  received 114 bytes  278.00 bytes/sec
total size is 378,419  speedup is 2,722.44
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
Wrote inspect data to must-gather.
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Gathering data for ns/kube-system...
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/kube-system...
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
Gathering data for ns/openshift-config-managed...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Gathering data for ns/openshift-config-managed...
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Error from server (AlreadyExists): error when creating "STDIN": daemonsets.apps "perf-node-gather-daemonset" already exists
daemonset.apps/perf-node-gather-daemonset created
Gathering data for ns/openshift-authentication...
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
Waiting for performance profile collector pods to become ready: 1
Waiting for performance profile collector pods to become ready: 1
Gathering data for ns/openshift-authentication...
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Waiting for performance profile collector pods to become ready: 2
Waiting for performance profile collector pods to become ready: 2
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 4
Waiting for performance profile collector pods to become ready: 4
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
14M	must-gather/network_logs/ovnk_database_store
ovnk_database_store/
ovnk_database_store/ovnkube-node-v96dr_nbdb
ovnk_database_store/ovnkube-node-v96dr_sbdb
ovnk_database_store/ovnkube-node-pk6hx_nbdb
ovnk_database_store/ovnkube-node-pk6hx_sbdb
INFO: Network log collection complete.
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 7
Waiting for performance profile collector pods to become ready: 7
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
du: cannot access 'must-gather/network_logs/ovnk_database_store': No such file or directory
tar: ovnk_database_store: Cannot stat: No such file or directory
tar: Exiting with failure status due to previous errors
INFO: Network log collection complete.
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 8
Waiting for performance profile collector pods to become ready: 8
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 9
Waiting for performance profile collector pods to become ready: 9
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 10
Waiting for performance profile collector pods to become ready: 10
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 12
Waiting for performance profile collector pods to become ready: 12
rm: cannot remove '../must-gather/monitoring/ca-bundle.crt': No such file or directory
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 24
Waiting for performance profile collector pods to become ready: 24
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 26
Waiting for performance profile collector pods to become ready: 26
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 30
Waiting for performance profile collector pods to become ready: 30
Waiting for performance profile collector pods to become ready: 31
Waiting for performance profile collector pods to become ready: 31
Waiting for performance profile collector pods to become ready: 32
Waiting for performance profile collector pods to become ready: 32
Waiting for performance profile collector pods to become ready: 33
Waiting for performance profile collector pods to become ready: 33
Gathering data for ns/openshift-cloud-controller-manager-operator...
Gathering data for ns/openshift-cloud-controller-manager...
Waiting for performance profile collector pods to become ready: 34
Waiting for performance profile collector pods to become ready: 34
Gathering data for ns/openshift-cloud-credential-operator...
Waiting for performance profile collector pods to become ready: 35
Waiting for performance profile collector pods to become ready: 35
Gathering data for ns/openshift-config-operator...
Gathering data for ns/openshift-console-operator...
Gathering data for ns/openshift-cloud-controller-manager-operator...
Gathering data for ns/openshift-console...
Waiting for performance profile collector pods to become ready: 36
Waiting for performance profile collector pods to become ready: 36
Gathering data for ns/openshift-cloud-controller-manager...
[root@INBACRNRDL0102 ~]# oc logs must-gather-rpxln -f
Defaulted container "gather" out of: gather, copy
Gathering data for ns/openshift-cluster-version...
Gathering data for ns/openshift-cluster-version...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Gathering data for ns/default...
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Waiting on subprocesses to finish execution.
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Gathering HAProxy config files
Waiting on subprocesses to finish execution.
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Gathering on-disk MachineConfig from degraded nodes
INFO: Gathering HAProxy config files
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Collecting host service logs for crio
INFO: Collecting host service logs for kubelet
INFO: Collecting host service logs for rpm-ostreed
INFO: Collecting host service logs for ostree-finalize-staged
INFO: Collecting host service logs for machine-config-daemon-firstboot
INFO: Collecting host service logs for machine-config-daemon-host
INFO: Collecting host service logs for NetworkManager
INFO: Collecting host service logs for openvswitch
INFO: Collecting host service logs for ovs-configuration
INFO: Collecting host service logs for ovsdb-server
INFO: Collecting host service logs for ovs-vswitchd
INFO: Waiting for worker host service log collection to complete ...
INFO: Waiting for node performance related collection to complete ...
WARNING: Collecting one or more kube-apiserver related logs on ALL masters in your cluster. This could take a large amount of time.
INFO: Waiting for node performance related collection to complete ...
Gathering data for ns/default...
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "metallb-operator" not detected. Skipping.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
Wrote inspect data to must-gather.
No resources found
No resources found
INFO: "metallb-operator" not detected. Skipping.
Wrote inspect data to must-gather.
INFO: Collecting Insights Archives from insights-operator-56546658bc-t4r9r
INFO: "sriov-network-operator" not detected. Skipping.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: Waiting for on-disk MachineConfig collection to complete ...
INFO: on-disk MachineConfig config collection complete.
INFO: "kubernetes-nmstate-operator" not detected. Skipping.
INFO: "sriov-network-operator" not detected. Skipping.
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
INFO: Waiting for HAProxy config collection to complete ...
Gathering data for ns/openshift...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
Wrote inspect data to must-gather.
No resources found
Wrote inspect data to must-gather.
No resources found
INFO: Waiting for HAProxy config collection to complete ...
W0215 23:03:09.312414    2104 util.go:195] skipping , failed to read event err: Object 'Kind' is missing in ''
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
tar: Removing leading `/' from member names
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
Wrote inspect data to must-gather.
receiving incremental file list
insights-operator/
insights-operator/insights-2025-02-15-214440.tar.gz

sent 47 bytes  received 378,667 bytes  757,428.00 bytes/sec
total size is 378,419  speedup is 1.00
error: the server doesn't have a resource type "multi-networkpolicy"
tar: Removing leading `/' from member names
INFO: HAProxy config collection complete.
error: the server doesn't have a resource type "multi-networkpolicy"
Wrote inspect data to must-gather.
Gathering data for ns/openshift...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
receiving incremental file list
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host

sent 25 bytes  received 114 bytes  278.00 bytes/sec
total size is 378,419  speedup is 2,722.44
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Started  downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-0.5g-deployment.lab
Wrote inspect data to must-gather.
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-1.5g-deployment.lab
INFO: Finished downloading kube-apiserver/termination.log from hub-ctlplane-2.5g-deployment.lab
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Wrote inspect data to must-gather.
INFO: Found 2 replicas - prometheus-k8s-0 prometheus-k8s-1
Gathering data for ns/kube-system...
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/kube-system...
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Gathering data for ns/openshift-config...
Wrote inspect data to must-gather.
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
Warning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
Wrote inspect data to must-gather.
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-1.5g-deployment.lab
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: INTERCONNECT MODE
INFO: Gathering ovn-kubernetes DBs
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
Gathering data for ns/openshift-config-managed...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Gathering OVN_Northbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Northbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Northbound from ovnkube-node-v96dr...
INFO: Gathering OVN_Southbound from ovnkube-node-pk6hx...
INFO: Gathering OVN_Southbound from ovnkube-node-rbwzq...
INFO: Gathering OVN_Southbound from ovnkube-node-v96dr...
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Gathering data for ns/openshift-etcd...
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Gathering data for ns/openshift-config-managed...
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
Error from server (NotFound): pods "hub-ctlplane-1.5g-deployment.lab" not found
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
tar: Removing leading `/' from member names
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Image with low level tools to use: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5b63e4af196e9ea0c44ee0ed5d623f920b1bfbebf9d89f38012543b07ba58488
INFO: Waiting for network log collection to complete ...
INFO: Waiting for ovnk database copies to complete ...
Error from server (AlreadyExists): error when creating "STDIN": daemonsets.apps "perf-node-gather-daemonset" already exists
daemonset.apps/perf-node-gather-daemonset created
Gathering data for ns/openshift-authentication...
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
INFO: Collecting /debug/api_priority_and_fairness endpoint from kube-apiserver-hub-ctlplane-2.5g-deployment.lab
Waiting for performance profile collector pods to become ready: 1
Waiting for performance profile collector pods to become ready: 1
Gathering data for ns/openshift-authentication...
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
error: error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Worker host service log collection to complete.
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Waiting for performance profile collector pods to become ready: 2
Waiting for performance profile collector pods to become ready: 2
Wrote inspect data to must-gather.
Wrote inspect data to must-gather.
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 3
Waiting for performance profile collector pods to become ready: 4
Waiting for performance profile collector pods to become ready: 4
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
14M	must-gather/network_logs/ovnk_database_store
ovnk_database_store/
ovnk_database_store/ovnkube-node-v96dr_nbdb
ovnk_database_store/ovnkube-node-v96dr_sbdb
ovnk_database_store/ovnkube-node-pk6hx_nbdb
ovnk_database_store/ovnkube-node-pk6hx_sbdb
INFO: Network log collection complete.
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 5
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 6
Waiting for performance profile collector pods to become ready: 7
Waiting for performance profile collector pods to become ready: 7
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
Error from server: error dialing backend: dial tcp 172.16.30.20:10250: connect: no route to host
INFO: Copying ovnk databases complete.
du: cannot access 'must-gather/network_logs/ovnk_database_store': No such file or directory
tar: ovnk_database_store: Cannot stat: No such file or directory
tar: Exiting with failure status due to previous errors
INFO: Network log collection complete.
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 8
Waiting for performance profile collector pods to become ready: 8
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 9
Waiting for performance profile collector pods to become ready: 9
Gathering data for ns/openshift-authentication-operator...
Waiting for performance profile collector pods to become ready: 10
Waiting for performance profile collector pods to become ready: 10
Gathering data for ns/openshift-ingress...
Gathering data for ns/openshift-oauth-apiserver...
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 11
Waiting for performance profile collector pods to become ready: 12
Waiting for performance profile collector pods to become ready: 12
rm: cannot remove '../must-gather/monitoring/ca-bundle.crt': No such file or directory
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 13
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 14
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 15
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 16
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 17
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 18
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 19
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 20
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 21
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 22
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 23
Waiting for performance profile collector pods to become ready: 24
Waiting for performance profile collector pods to become ready: 24
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 25
Waiting for performance profile collector pods to become ready: 26
Waiting for performance profile collector pods to become ready: 26
Gathering data for ns/openshift-machine-api...
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 27
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 28
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 29
Waiting for performance profile collector pods to become ready: 30
Waiting for performance profile collector pods to become ready: 30
Waiting for performance profile collector pods to become ready: 31
Waiting for performance profile collector pods to become ready: 31
Waiting for performance profile collector pods to become ready: 32
Waiting for performance profile collector pods to become ready: 32
Waiting for performance profile collector pods to become ready: 33
Waiting for performance profile collector pods to become ready: 33
Gathering data for ns/openshift-cloud-controller-manager-operator...
Gathering data for ns/openshift-cloud-controller-manager...
Waiting for performance profile collector pods to become ready: 34
Waiting for performance profile collector pods to become ready: 34
Gathering data for ns/openshift-cloud-credential-operator...
Waiting for performance profile collector pods to become ready: 35
Waiting for performance profile collector pods to become ready: 35
Gathering data for ns/openshift-config-operator...
Gathering data for ns/openshift-console-operator...
Gathering data for ns/openshift-cloud-controller-manager-operator...
Gathering data for ns/openshift-console...
Waiting for performance profile collector pods to become ready: 36
Waiting for performance profile collector pods to become ready: 36
Gathering data for ns/openshift-cloud-controller-manager...
Gathering data for ns/openshift-cloud-credential-operator...
Waiting for performance profile collector pods to become ready: 37
Waiting for performance profile collector pods to become ready: 37
Gathering data for ns/openshift-config-operator...
Gathering data for ns/openshift-cluster-storage-operator...
Waiting for performance profile collector pods to become ready: 38
Waiting for performance profile collector pods to become ready: 38
Gathering data for ns/openshift-console-operator...
Gathering data for ns/openshift-dns-operator...
Gathering data for ns/openshift-console...
Gathering data for ns/openshift-dns...
Waiting for performance profile collector pods to become ready: 39
Waiting for performance profile collector pods to become ready: 39
Waiting for performance profile collector pods to become ready: 40
Waiting for performance profile collector pods to become ready: 40
Gathering data for ns/openshift-cluster-storage-operator...
Waiting for performance profile collector pods to become ready: 41
Gathering data for ns/openshift-dns-operator...
Waiting for performance profile collector pods to become ready: 41
Gathering data for ns/openshift-dns...
Waiting for performance profile collector pods to become ready: 42
Waiting for performance profile collector pods to become ready: 42
Waiting for performance profile collector pods to become ready: 43
Waiting for performance profile collector pods to become ready: 43
Waiting for performance profile collector pods to become ready: 44
Waiting for performance profile collector pods to become ready: 44
Waiting for performance profile collector pods to become ready: 45
Waiting for performance profile collector pods to become ready: 45
Waiting for performance profile collector pods to become ready: 46
Waiting for performance profile collector pods to become ready: 46
Waiting for performance profile collector pods to become ready: 47
Waiting for performance profile collector pods to become ready: 47
Waiting for performance profile collector pods to become ready: 48
Waiting for performance profile collector pods to become ready: 48
Waiting for performance profile collector pods to become ready: 49
Waiting for performance profile collector pods to become ready: 49
Waiting for performance profile collector pods to become ready: 50
Waiting for performance profile collector pods to become ready: 50
Waiting for performance profile collector pods to become ready: 51
Waiting for performance profile collector pods to become ready: 51
Waiting for performance profile collector pods to become ready: 52
Waiting for performance profile collector pods to become ready: 52
Waiting for performance profile collector pods to become ready: 53
Waiting for performance profile collector pods to become ready: 53
Waiting for performance profile collector pods to become ready: 54
Waiting for performance profile collector pods to become ready: 54
Waiting for performance profile collector pods to become ready: 55
Waiting for performance profile collector pods to become ready: 55
Waiting for performance profile collector pods to become ready: 56
Waiting for performance profile collector pods to become ready: 56
Waiting for performance profile collector pods to become ready: 57
Waiting for performance profile collector pods to become ready: 57
Waiting for performance profile collector pods to become ready: 58
Waiting for performance profile collector pods to become ready: 58
Waiting for performance profile collector pods to become ready: 59
Waiting for performance profile collector pods to become ready: 59
Waiting for performance profile collector pods to become ready: 60
Waiting for performance profile collector pods to become ready: 60
Waiting for performance profile collector pods to become ready: 61
Waiting for performance profile collector pods to become ready: 61
Waiting for performance profile collector pods to become ready: 62
Waiting for performance profile collector pods to become ready: 62
Waiting for performance profile collector pods to become ready: 63
Gathering data for ns/openshift-etcd-operator...
Waiting for performance profile collector pods to become ready: 63
Gathering data for ns/openshift-etcd...
Waiting for performance profile collector pods to become ready: 64
Waiting for performance profile collector pods to become ready: 64
Waiting for performance profile collector pods to become ready: 65
Waiting for performance profile collector pods to become ready: 65
Gathering data for ns/openshift-etcd-operator...
Gathering data for ns/openshift-etcd...
Waiting for performance profile collector pods to become ready: 66
Waiting for performance profile collector pods to become ready: 66
Waiting for performance profile collector pods to become ready: 67
Waiting for performance profile collector pods to become ready: 67
Waiting for performance profile collector pods to become ready: 68
Waiting for performance profile collector pods to become ready: 68
Waiting for performance profile collector pods to become ready: 69
Waiting for performance profile collector pods to become ready: 69
Waiting for performance profile collector pods to become ready: 70
Waiting for performance profile collector pods to become ready: 70
Waiting for performance profile collector pods to become ready: 71
Waiting for performance profile collector pods to become ready: 71
Waiting for performance profile collector pods to become ready: 72
Waiting for performance profile collector pods to become ready: 72
Waiting for performance profile collector pods to become ready: 73
Waiting for performance profile collector pods to become ready: 73
Waiting for performance profile collector pods to become ready: 74
Waiting for performance profile collector pods to become ready: 74
Waiting for performance profile collector pods to become ready: 75
Waiting for performance profile collector pods to become ready: 75
Waiting for performance profile collector pods to become ready: 76
Waiting for performance profile collector pods to become ready: 76
Waiting for performance profile collector pods to become ready: 77
Waiting for performance profile collector pods to become ready: 77
Waiting for performance profile collector pods to become ready: 78
Waiting for performance profile collector pods to become ready: 78
Waiting for performance profile collector pods to become ready: 79
Waiting for performance profile collector pods to become ready: 79
Waiting for performance profile collector pods to become ready: 80
Waiting for performance profile collector pods to become ready: 80
Waiting for performance profile collector pods to become ready: 81
Waiting for performance profile collector pods to become ready: 81
Waiting for performance profile collector pods to become ready: 82
Waiting for performance profile collector pods to become ready: 82
Waiting for performance profile collector pods to become ready: 83
Waiting for performance profile collector pods to become ready: 83
Waiting for performance profile collector pods to become ready: 84
Waiting for performance profile collector pods to become ready: 84
Waiting for performance profile collector pods to become ready: 85
Waiting for performance profile collector pods to become ready: 85
Waiting for performance profile collector pods to become ready: 86
Waiting for performance profile collector pods to become ready: 86
Waiting for performance profile collector pods to become ready: 87
Waiting for performance profile collector pods to become ready: 87
Waiting for performance profile collector pods to become ready: 88
Waiting for performance profile collector pods to become ready: 88
Waiting for performance profile collector pods to become ready: 89
Waiting for performance profile collector pods to become ready: 89
Waiting for performance profile collector pods to become ready: 90
Waiting for performance profile collector pods to become ready: 90
Waiting for performance profile collector pods to become ready: 91
Waiting for performance profile collector pods to become ready: 91
Waiting for performance profile collector pods to become ready: 92
Waiting for performance profile collector pods to become ready: 92
Waiting for performance profile collector pods to become ready: 93
Waiting for performance profile collector pods to become ready: 93
Waiting for performance profile collector pods to become ready: 94
Waiting for performance profile collector pods to become ready: 94
Waiting for performance profile collector pods to become ready: 95
Waiting for performance profile collector pods to become ready: 95
Waiting for performance profile collector pods to become ready: 96
Waiting for performance profile collector pods to become ready: 96
Waiting for performance profile collector pods to become ready: 97
Waiting for performance profile collector pods to become ready: 97
Waiting for performance profile collector pods to become ready: 98
Waiting for performance profile collector pods to become ready: 98
Waiting for performance profile collector pods to become ready: 99
Waiting for performance profile collector pods to become ready: 99
Waiting for performance profile collector pods to become ready: 100
Waiting for performance profile collector pods to become ready: 100
Waiting for performance profile collector pods to become ready: 101
Waiting for performance profile collector pods to become ready: 101
Waiting for performance profile collector pods to become ready: 102
Waiting for performance profile collector pods to become ready: 102
Waiting for performance profile collector pods to become ready: 103
Waiting for performance profile collector pods to become ready: 103
Waiting for performance profile collector pods to become ready: 104
Waiting for performance profile collector pods to become ready: 104
Waiting for performance profile collector pods to become ready: 105
Waiting for performance profile collector pods to become ready: 105
Waiting for performance profile collector pods to become ready: 106
Waiting for performance profile collector pods to become ready: 106
Waiting for performance profile collector pods to become ready: 107
Waiting for performance profile collector pods to become ready: 107
Waiting for performance profile collector pods to become ready: 108
Waiting for performance profile collector pods to become ready: 108
Waiting for performance profile collector pods to become ready: 109
Waiting for performance profile collector pods to become ready: 109
Waiting for performance profile collector pods to become ready: 110
Waiting for performance profile collector pods to become ready: 110
Wrote inspect data to must-gather.
error: inspection completed with the errors occurred while gathering data:
    one or more errors occurred while gathering pod-specific data for namespace: openshift-etcd

    [one or more errors occurred while gathering container data for pod etcd-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod etcd-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]]
Wrote inspect data to must-gather.
error: inspection completed with the errors occurred while gathering data:
    one or more errors occurred while gathering pod-specific data for namespace: openshift-etcd

    [one or more errors occurred while gathering container data for pod etcd-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod etcd-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]]
Waiting for performance profile collector pods to become ready: 111
Waiting for performance profile collector pods to become ready: 111
Waiting for performance profile collector pods to become ready: 112
Waiting for performance profile collector pods to become ready: 112
Waiting for performance profile collector pods to become ready: 113
Waiting for performance profile collector pods to become ready: 113
Waiting for performance profile collector pods to become ready: 114
Waiting for performance profile collector pods to become ready: 114
Waiting for performance profile collector pods to become ready: 115
Waiting for performance profile collector pods to become ready: 115
Waiting for performance profile collector pods to become ready: 116
Waiting for performance profile collector pods to become ready: 116
Waiting for performance profile collector pods to become ready: 117
Waiting for performance profile collector pods to become ready: 117
Waiting for performance profile collector pods to become ready: 118
Waiting for performance profile collector pods to become ready: 118
Waiting for performance profile collector pods to become ready: 119
Waiting for performance profile collector pods to become ready: 119
Waiting for performance profile collector pods to become ready: 120
Waiting for performance profile collector pods to become ready: 120
Waiting for performance profile collector pods to become ready: 121
Waiting for performance profile collector pods to become ready: 121
Waiting for performance profile collector pods to become ready: 122
Waiting for performance profile collector pods to become ready: 122
Waiting for performance profile collector pods to become ready: 123
Waiting for performance profile collector pods to become ready: 123
Waiting for performance profile collector pods to become ready: 124
Waiting for performance profile collector pods to become ready: 124
Waiting for performance profile collector pods to become ready: 125
Waiting for performance profile collector pods to become ready: 125
Waiting for performance profile collector pods to become ready: 126
Waiting for performance profile collector pods to become ready: 126
Waiting for performance profile collector pods to become ready: 127
Waiting for performance profile collector pods to become ready: 127
Waiting for performance profile collector pods to become ready: 128
Waiting for performance profile collector pods to become ready: 128
Waiting for performance profile collector pods to become ready: 129
Waiting for performance profile collector pods to become ready: 129
Waiting for performance profile collector pods to become ready: 130
Waiting for performance profile collector pods to become ready: 130
Waiting for performance profile collector pods to become ready: 131
Waiting for performance profile collector pods to become ready: 131
Waiting for performance profile collector pods to become ready: 132
Waiting for performance profile collector pods to become ready: 132
Waiting for performance profile collector pods to become ready: 133
Waiting for performance profile collector pods to become ready: 133
Waiting for performance profile collector pods to become ready: 134
Waiting for performance profile collector pods to become ready: 134
Waiting for performance profile collector pods to become ready: 135
Waiting for performance profile collector pods to become ready: 135
Waiting for performance profile collector pods to become ready: 136
Waiting for performance profile collector pods to become ready: 136
Waiting for performance profile collector pods to become ready: 137
Waiting for performance profile collector pods to become ready: 137
Waiting for performance profile collector pods to become ready: 138
Waiting for performance profile collector pods to become ready: 138
Waiting for performance profile collector pods to become ready: 139
Waiting for performance profile collector pods to become ready: 139
Waiting for performance profile collector pods to become ready: 140
Waiting for performance profile collector pods to become ready: 140
Waiting for performance profile collector pods to become ready: 141
Waiting for performance profile collector pods to become ready: 141
Waiting for performance profile collector pods to become ready: 142
Waiting for performance profile collector pods to become ready: 142
Waiting for performance profile collector pods to become ready: 143
Waiting for performance profile collector pods to become ready: 143
Waiting for performance profile collector pods to become ready: 144
Waiting for performance profile collector pods to become ready: 144
Waiting for performance profile collector pods to become ready: 145
Waiting for performance profile collector pods to become ready: 145
Waiting for performance profile collector pods to become ready: 146
Waiting for performance profile collector pods to become ready: 146
Waiting for performance profile collector pods to become ready: 147
Waiting for performance profile collector pods to become ready: 147
Waiting for performance profile collector pods to become ready: 148
Waiting for performance profile collector pods to become ready: 148
Waiting for performance profile collector pods to become ready: 149
Waiting for performance profile collector pods to become ready: 149
Waiting for performance profile collector pods to become ready: 150
Waiting for performance profile collector pods to become ready: 150
Waiting for performance profile collector pods to become ready: 151
Waiting for performance profile collector pods to become ready: 151
Waiting for performance profile collector pods to become ready: 152
Waiting for performance profile collector pods to become ready: 152
Waiting for performance profile collector pods to become ready: 153
Waiting for performance profile collector pods to become ready: 153
Waiting for performance profile collector pods to become ready: 154
Waiting for performance profile collector pods to become ready: 154
Waiting for performance profile collector pods to become ready: 155
Waiting for performance profile collector pods to become ready: 155
Waiting for performance profile collector pods to become ready: 156
Waiting for performance profile collector pods to become ready: 156
Waiting for performance profile collector pods to become ready: 157
Waiting for performance profile collector pods to become ready: 157
Waiting for performance profile collector pods to become ready: 158
Waiting for performance profile collector pods to become ready: 158
Waiting for performance profile collector pods to become ready: 159
Waiting for performance profile collector pods to become ready: 159
Waiting for performance profile collector pods to become ready: 160
Waiting for performance profile collector pods to become ready: 160
Waiting for performance profile collector pods to become ready: 161
Waiting for performance profile collector pods to become ready: 161
Waiting for performance profile collector pods to become ready: 162
Waiting for performance profile collector pods to become ready: 162
Waiting for performance profile collector pods to become ready: 163
Waiting for performance profile collector pods to become ready: 163
Waiting for performance profile collector pods to become ready: 164
Waiting for performance profile collector pods to become ready: 164
Waiting for performance profile collector pods to become ready: 165
Waiting for performance profile collector pods to become ready: 165
Waiting for performance profile collector pods to become ready: 166
Waiting for performance profile collector pods to become ready: 166
Waiting for performance profile collector pods to become ready: 167
Waiting for performance profile collector pods to become ready: 167
Waiting for performance profile collector pods to become ready: 168
Waiting for performance profile collector pods to become ready: 168
Waiting for performance profile collector pods to become ready: 169
Waiting for performance profile collector pods to become ready: 169
Waiting for performance profile collector pods to become ready: 170
Waiting for performance profile collector pods to become ready: 170
Waiting for performance profile collector pods to become ready: 171
Waiting for performance profile collector pods to become ready: 171
Waiting for performance profile collector pods to become ready: 172
Waiting for performance profile collector pods to become ready: 172
Waiting for performance profile collector pods to become ready: 173
Waiting for performance profile collector pods to become ready: 173
Waiting for performance profile collector pods to become ready: 174
Waiting for performance profile collector pods to become ready: 174
Waiting for performance profile collector pods to become ready: 175
Waiting for performance profile collector pods to become ready: 175
Waiting for performance profile collector pods to become ready: 176
Waiting for performance profile collector pods to become ready: 176
Gathering data for ns/openshift-image-registry...
Gathering data for ns/openshift-image-registry...
Waiting for performance profile collector pods to become ready: 177
Waiting for performance profile collector pods to become ready: 177
Waiting for performance profile collector pods to become ready: 178
Waiting for performance profile collector pods to become ready: 178
Waiting for performance profile collector pods to become ready: 179
Waiting for performance profile collector pods to become ready: 179
Waiting for performance profile collector pods to become ready: 180
Waiting for performance profile collector pods to become ready: 180
Waiting for performance profile collector pods to become ready: 181
Waiting for performance profile collector pods to become ready: 181
Waiting for performance profile collector pods to become ready: 182
Waiting for performance profile collector pods to become ready: 182
Waiting for performance profile collector pods to become ready: 183
Waiting for performance profile collector pods to become ready: 183
Waiting for performance profile collector pods to become ready: 184
Waiting for performance profile collector pods to become ready: 184
Gathering data for ns/openshift-ingress-operator...
Waiting for performance profile collector pods to become ready: 185
Waiting for performance profile collector pods to become ready: 185
Gathering data for ns/openshift-ingress-canary...
Gathering data for ns/openshift-ingress-operator...
Gathering data for ns/openshift-ingress-canary...
Waiting for performance profile collector pods to become ready: 186
Waiting for performance profile collector pods to become ready: 186
Waiting for performance profile collector pods to become ready: 187
Waiting for performance profile collector pods to become ready: 187
Waiting for performance profile collector pods to become ready: 188
Waiting for performance profile collector pods to become ready: 188
Waiting for performance profile collector pods to become ready: 189
Waiting for performance profile collector pods to become ready: 189
Waiting for performance profile collector pods to become ready: 190
Waiting for performance profile collector pods to become ready: 190
Waiting for performance profile collector pods to become ready: 191
Waiting for performance profile collector pods to become ready: 191
Waiting for performance profile collector pods to become ready: 192
Waiting for performance profile collector pods to become ready: 192
Gathering data for ns/openshift-insights...
Waiting for performance profile collector pods to become ready: 193
Waiting for performance profile collector pods to become ready: 193
Gathering data for ns/openshift-insights...
Waiting for performance profile collector pods to become ready: 194
Waiting for performance profile collector pods to become ready: 194
Gathering data for ns/openshift-monitoring...
Gathering data for ns/openshift-monitoring...
Waiting for performance profile collector pods to become ready: 195
Waiting for performance profile collector pods to become ready: 195
Waiting for performance profile collector pods to become ready: 196
Waiting for performance profile collector pods to become ready: 196
Waiting for performance profile collector pods to become ready: 197
Waiting for performance profile collector pods to become ready: 197
Waiting for performance profile collector pods to become ready: 198
Waiting for performance profile collector pods to become ready: 198
Waiting for performance profile collector pods to become ready: 199
Waiting for performance profile collector pods to become ready: 199
Waiting for performance profile collector pods to become ready: 200
Waiting for performance profile collector pods to become ready: 200
Waiting for performance profile collector pods to become ready: 201
Waiting for performance profile collector pods to become ready: 201
Waiting for performance profile collector pods to become ready: 202
Waiting for performance profile collector pods to become ready: 202
Waiting for performance profile collector pods to become ready: 203
Waiting for performance profile collector pods to become ready: 203
Waiting for performance profile collector pods to become ready: 204
Waiting for performance profile collector pods to become ready: 204
Waiting for performance profile collector pods to become ready: 205
Waiting for performance profile collector pods to become ready: 205
Waiting for performance profile collector pods to become ready: 206
Waiting for performance profile collector pods to become ready: 206
Waiting for performance profile collector pods to become ready: 207
Waiting for performance profile collector pods to become ready: 207
Waiting for performance profile collector pods to become ready: 208
Waiting for performance profile collector pods to become ready: 208
Waiting for performance profile collector pods to become ready: 209
Waiting for performance profile collector pods to become ready: 209
Waiting for performance profile collector pods to become ready: 210
Waiting for performance profile collector pods to become ready: 210
Waiting for performance profile collector pods to become ready: 211
Waiting for performance profile collector pods to become ready: 211
Waiting for performance profile collector pods to become ready: 212
Waiting for performance profile collector pods to become ready: 212
Waiting for performance profile collector pods to become ready: 213
Waiting for performance profile collector pods to become ready: 213
Waiting for performance profile collector pods to become ready: 214
Waiting for performance profile collector pods to become ready: 214
Waiting for performance profile collector pods to become ready: 215
Waiting for performance profile collector pods to become ready: 215
Waiting for performance profile collector pods to become ready: 216
Waiting for performance profile collector pods to become ready: 216
Waiting for performance profile collector pods to become ready: 217
Waiting for performance profile collector pods to become ready: 217
Waiting for performance profile collector pods to become ready: 218
Waiting for performance profile collector pods to become ready: 218
Waiting for performance profile collector pods to become ready: 219
Waiting for performance profile collector pods to become ready: 219
Waiting for performance profile collector pods to become ready: 220
Waiting for performance profile collector pods to become ready: 220
Waiting for performance profile collector pods to become ready: 221
Waiting for performance profile collector pods to become ready: 221
Waiting for performance profile collector pods to become ready: 222
Waiting for performance profile collector pods to become ready: 222
Waiting for performance profile collector pods to become ready: 223
Waiting for performance profile collector pods to become ready: 223
Waiting for performance profile collector pods to become ready: 224
Waiting for performance profile collector pods to become ready: 224
Waiting for performance profile collector pods to become ready: 225
Waiting for performance profile collector pods to become ready: 225
Waiting for performance profile collector pods to become ready: 226
Waiting for performance profile collector pods to become ready: 226
Waiting for performance profile collector pods to become ready: 227
Waiting for performance profile collector pods to become ready: 227
Waiting for performance profile collector pods to become ready: 228
Waiting for performance profile collector pods to become ready: 228
Waiting for performance profile collector pods to become ready: 229
Waiting for performance profile collector pods to become ready: 229
Waiting for performance profile collector pods to become ready: 230
Waiting for performance profile collector pods to become ready: 230
Waiting for performance profile collector pods to become ready: 231
Waiting for performance profile collector pods to become ready: 231
Waiting for performance profile collector pods to become ready: 232
Waiting for performance profile collector pods to become ready: 232
Waiting for performance profile collector pods to become ready: 233
Waiting for performance profile collector pods to become ready: 233
Waiting for performance profile collector pods to become ready: 234
Waiting for performance profile collector pods to become ready: 234
Waiting for performance profile collector pods to become ready: 235
Waiting for performance profile collector pods to become ready: 235
Waiting for performance profile collector pods to become ready: 236
Waiting for performance profile collector pods to become ready: 236
Waiting for performance profile collector pods to become ready: 237
Waiting for performance profile collector pods to become ready: 237
Waiting for performance profile collector pods to become ready: 238
Waiting for performance profile collector pods to become ready: 238
Waiting for performance profile collector pods to become ready: 239
Waiting for performance profile collector pods to become ready: 239
Waiting for performance profile collector pods to become ready: 240
Waiting for performance profile collector pods to become ready: 240
Waiting for performance profile collector pods to become ready: 241
Waiting for performance profile collector pods to become ready: 241
Waiting for performance profile collector pods to become ready: 242
Waiting for performance profile collector pods to become ready: 242
Waiting for performance profile collector pods to become ready: 243
Waiting for performance profile collector pods to become ready: 243
Waiting for performance profile collector pods to become ready: 244
Waiting for performance profile collector pods to become ready: 244
Waiting for performance profile collector pods to become ready: 245
Waiting for performance profile collector pods to become ready: 245
Waiting for performance profile collector pods to become ready: 246
Waiting for performance profile collector pods to become ready: 246
Waiting for performance profile collector pods to become ready: 247
Waiting for performance profile collector pods to become ready: 247
Waiting for performance profile collector pods to become ready: 248
Waiting for performance profile collector pods to become ready: 248
Waiting for performance profile collector pods to become ready: 249
Waiting for performance profile collector pods to become ready: 249
Waiting for performance profile collector pods to become ready: 250
Waiting for performance profile collector pods to become ready: 250
Waiting for performance profile collector pods to become ready: 251
Waiting for performance profile collector pods to become ready: 251
Waiting for performance profile collector pods to become ready: 252
Waiting for performance profile collector pods to become ready: 252
Waiting for performance profile collector pods to become ready: 253
Waiting for performance profile collector pods to become ready: 253
Waiting for performance profile collector pods to become ready: 254
Waiting for performance profile collector pods to become ready: 254
Waiting for performance profile collector pods to become ready: 255
Waiting for performance profile collector pods to become ready: 255
Waiting for performance profile collector pods to become ready: 256
Waiting for performance profile collector pods to become ready: 256
Waiting for performance profile collector pods to become ready: 257
Waiting for performance profile collector pods to become ready: 257
Waiting for performance profile collector pods to become ready: 258
Waiting for performance profile collector pods to become ready: 258
Waiting for performance profile collector pods to become ready: 259
Waiting for performance profile collector pods to become ready: 259
Waiting for performance profile collector pods to become ready: 260
Waiting for performance profile collector pods to become ready: 260
Waiting for performance profile collector pods to become ready: 261
Waiting for performance profile collector pods to become ready: 261
Waiting for performance profile collector pods to become ready: 262
Waiting for performance profile collector pods to become ready: 262
Waiting for performance profile collector pods to become ready: 263
Waiting for performance profile collector pods to become ready: 263
Waiting for performance profile collector pods to become ready: 264
Waiting for performance profile collector pods to become ready: 264
Waiting for performance profile collector pods to become ready: 265
Waiting for performance profile collector pods to become ready: 265
Waiting for performance profile collector pods to become ready: 266
Waiting for performance profile collector pods to become ready: 266
Waiting for performance profile collector pods to become ready: 267
Waiting for performance profile collector pods to become ready: 267
Waiting for performance profile collector pods to become ready: 268
Waiting for performance profile collector pods to become ready: 268
Waiting for performance profile collector pods to become ready: 269
Waiting for performance profile collector pods to become ready: 269
Waiting for performance profile collector pods to become ready: 270
Waiting for performance profile collector pods to become ready: 270
Waiting for performance profile collector pods to become ready: 271
Waiting for performance profile collector pods to become ready: 271
Waiting for performance profile collector pods to become ready: 272
Waiting for performance profile collector pods to become ready: 272
Waiting for performance profile collector pods to become ready: 273
Waiting for performance profile collector pods to become ready: 273
Waiting for performance profile collector pods to become ready: 274
Waiting for performance profile collector pods to become ready: 274
Waiting for performance profile collector pods to become ready: 275
Waiting for performance profile collector pods to become ready: 275
Waiting for performance profile collector pods to become ready: 276
Waiting for performance profile collector pods to become ready: 276
Waiting for performance profile collector pods to become ready: 277
Waiting for performance profile collector pods to become ready: 277
Waiting for performance profile collector pods to become ready: 278
Waiting for performance profile collector pods to become ready: 278
Waiting for performance profile collector pods to become ready: 279
Waiting for performance profile collector pods to become ready: 279
Waiting for performance profile collector pods to become ready: 280
Waiting for performance profile collector pods to become ready: 280
Waiting for performance profile collector pods to become ready: 281
Waiting for performance profile collector pods to become ready: 281
Waiting for performance profile collector pods to become ready: 282
Waiting for performance profile collector pods to become ready: 282
Gathering data for ns/openshift-operators...
Gathering data for ns/hypershift...
Waiting for performance profile collector pods to become ready: 283
Waiting for performance profile collector pods to become ready: 283
Gathering data for ns/open-cluster-management...
Waiting for performance profile collector pods to become ready: 284
Waiting for performance profile collector pods to become ready: 284
Gathering data for ns/openshift-operators...
Waiting for performance profile collector pods to become ready: 285
Waiting for performance profile collector pods to become ready: 285
Gathering data for ns/hypershift...
Waiting for performance profile collector pods to become ready: 286
Waiting for performance profile collector pods to become ready: 286
Gathering data for ns/open-cluster-management...
Waiting for performance profile collector pods to become ready: 287
Waiting for performance profile collector pods to become ready: 287
Waiting for performance profile collector pods to become ready: 288
Waiting for performance profile collector pods to become ready: 288
Waiting for performance profile collector pods to become ready: 289
Waiting for performance profile collector pods to become ready: 289
Waiting for performance profile collector pods to become ready: 290
Waiting for performance profile collector pods to become ready: 290
Waiting for performance profile collector pods to become ready: 291
Waiting for performance profile collector pods to become ready: 291
Waiting for performance profile collector pods to become ready: 292
Waiting for performance profile collector pods to become ready: 292
Gathering data for ns/openshift-cluster-node-tuning-operator...
Waiting for performance profile collector pods to become ready: 293
Waiting for performance profile collector pods to become ready: 293
Waiting for performance profile collector pods to become ready: 294
Waiting for performance profile collector pods to become ready: 294
Waiting for performance profile collector pods to become ready: 295
Waiting for performance profile collector pods to become ready: 295
Gathering data for ns/openshift-cluster-node-tuning-operator...
Waiting for performance profile collector pods to become ready: 296
Waiting for performance profile collector pods to become ready: 296
Waiting for performance profile collector pods to become ready: 297
Waiting for performance profile collector pods to become ready: 297
Waiting for performance profile collector pods to become ready: 298
Waiting for performance profile collector pods to become ready: 298
Waiting for performance profile collector pods to become ready: 299
Waiting for performance profile collector pods to become ready: 299
Waiting for performance profile collector pods to become ready: 300
Waiting for performance profile collector pods to become ready: 300
Collecting performance related data for node hub-ctlplane-2.5g-deployment.lab
Collecting performance related data for node hub-ctlplane-1.5g-deployment.lab
Collecting performance related data for node hub-ctlplane-2.5g-deployment.lab
Collecting performance related data for node hub-ctlplane-1.5g-deployment.lab
Gathering data for ns/openshift-kube-apiserver-operator...
Gathering data for ns/openshift-kube-apiserver...
Gathering data for ns/openshift-kube-apiserver-operator...
Gathering data for ns/openshift-kube-apiserver...
Collecting kubelet logs for node hub-ctlplane-2.5g-deployment.lab
Collecting kubelet logs for node hub-ctlplane-1.5g-deployment.lab
daemonset.apps "perf-node-gather-daemonset" deleted
INFO: Node performance data collection complete.
error: Internal error occurred: error executing command in container: signal: killed
error: Internal error occurred: error executing command in container: signal: killed
Collecting kubelet logs for node hub-ctlplane-2.5g-deployment.lab
Collecting kubelet logs for node hub-ctlplane-1.5g-deployment.lab
Error from server (NotFound): daemonsets.apps "perf-node-gather-daemonset" not found
INFO: Node performance data collection complete.
Gathering data for ns/default...
Gathering data for ns/open-cluster-management-hub...
Gathering data for ns/multicluster-engine...
Gathering data for ns/default...
Gathering data for ns/open-cluster-management-hub...
Gathering data for ns/multicluster-engine...
Gathering data for ns/openshift-multus...
Gathering data for ns/openshift-multus...
Gathering data for ns/openshift-storage...
Gathering data for ns/openshift-storage...
Gathering data for ns/openshift-kmm-hub...
Gathering data for ns/openshift-kmm-hub...
Gathering data for ns/openshift-kube-controller-manager...
Gathering data for ns/openshift-kube-controller-manager...
Gathering data for ns/openshift-kube-controller-manager-operator...
Gathering data for ns/kube-system...
Gathering data for ns/openshift-kube-scheduler...
Gathering data for ns/openshift-kube-controller-manager-operator...
Gathering data for ns/kube-system...
Gathering data for ns/openshift-kube-scheduler...
Gathering data for ns/openshift-kube-scheduler-operator...
Gathering data for ns/openshift-kube-storage-version-migrator...
Gathering data for ns/openshift-kube-storage-version-migrator-operator...
Gathering data for ns/openshift-cluster-machine-approver...
Gathering data for ns/openshift-machine-config-operator...
Gathering data for ns/openshift-kube-scheduler-operator...
Gathering data for ns/openshift-kube-storage-version-migrator...
Gathering data for ns/openshift-kube-storage-version-migrator-operator...
Gathering data for ns/openshift-cluster-machine-approver...
Gathering data for ns/openshift-machine-config-operator...
Gathering data for ns/openshift-kni-infra...
Gathering data for ns/openshift-openstack-infra...
Gathering data for ns/openshift-ovirt-infra...
Gathering data for ns/openshift-vsphere-infra...
Gathering data for ns/openshift-nutanix-infra...
Gathering data for ns/openshift-cloud-platform-infra...
Gathering data for ns/openshift-marketplace...
Gathering data for ns/openshift-kni-infra...
Gathering data for ns/openshift-openstack-infra...
Gathering data for ns/openshift-user-workload-monitoring...
Gathering data for ns/openshift-ovirt-infra...
Gathering data for ns/openshift-vsphere-infra...
Gathering data for ns/openshift-nutanix-infra...
Gathering data for ns/openshift-cloud-platform-infra...
Gathering data for ns/openshift-marketplace...
Gathering data for ns/openshift-user-workload-monitoring...
Gathering data for ns/openshift-ovn-kubernetes...
Gathering data for ns/openshift-ovn-kubernetes...
Gathering data for ns/openshift-host-network...
Gathering data for ns/openshift-network-diagnostics...
Gathering data for ns/openshift-host-network...
Gathering data for ns/openshift-network-diagnostics...
Gathering data for ns/openshift-network-node-identity...
Gathering data for ns/openshift-network-node-identity...
Gathering data for ns/openshift-network-console...
Gathering data for ns/openshift-network-operator...
Gathering data for ns/openshift-network-console...
Gathering data for ns/openshift-network-operator...
Gathering data for ns/openshift-cloud-network-config-controller...
Gathering data for ns/openshift-apiserver-operator...
Gathering data for ns/openshift-apiserver...
Gathering data for ns/openshift-cloud-network-config-controller...
Gathering data for ns/openshift-apiserver-operator...
Gathering data for ns/openshift-apiserver...
Gathering data for ns/openshift-controller-manager-operator...
Gathering data for ns/openshift-controller-manager...
Gathering data for ns/openshift-controller-manager-operator...
Gathering data for ns/openshift-controller-manager...
Gathering data for ns/openshift-route-controller-manager...
Gathering data for ns/openshift-route-controller-manager...
Gathering data for ns/openshift-cluster-samples-operator...
Gathering data for ns/openshift-operator-lifecycle-manager...
Gathering data for ns/openshift-service-ca-operator...
Gathering data for ns/openshift-service-ca...
Gathering data for ns/openshift-cluster-csi-drivers...
Wrote inspect data to must-gather.
error: inspection completed with the errors occurred while gathering data:
    [skipping gathering namespaces/openshift-authentication due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-authentication

    one or more errors occurred while gathering container data for pod oauth-openshift-6d798f766c-qdfqm:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-authentication/oauth-openshift-6d798f766c-qdfqm/oauth-openshift?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-authentication/oauth-openshift-6d798f766c-qdfqm/oauth-openshift?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-oauth-apiserver due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-oauth-apiserver

    one or more errors occurred while gathering container data for pod apiserver-65676db74b-scpbf:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/oauth-apiserver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/oauth-apiserver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/fix-audit-permissions?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/fix-audit-permissions?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-machine-api due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-machine-api

    one or more errors occurred while gathering container data for pod ironic-proxy-r2ssq:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-api/ironic-proxy-r2ssq/ironic-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-api/ironic-proxy-r2ssq/ironic-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-dns due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-dns

    [one or more errors occurred while gathering container data for pod dns-default-74tff:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/dns?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/dns?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod node-resolver-v4hjb:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-dns/node-resolver-v4hjb/dns-node-resolver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/node-resolver-v4hjb/dns-node-resolver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-etcd due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-etcd

    [one or more errors occurred while gathering container data for pod etcd-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod etcd-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-image-registry due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-image-registry

    one or more errors occurred while gathering container data for pod node-ca-gnpnf:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-image-registry/node-ca-gnpnf/node-ca?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-image-registry/node-ca-gnpnf/node-ca?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-ingress-canary due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-ingress-canary

    one or more errors occurred while gathering container data for pod ingress-canary-w85b8:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-ingress-canary/ingress-canary-w85b8/serve-healthcheck-canary?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ingress-canary/ingress-canary-w85b8/serve-healthcheck-canary?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering secrets/support due to error: secrets "support" not found, skipping gathering customresourcedefinitions.apiextensions.k8s.io due to error: skipping gathering namespaces/openshift-monitoring due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-monitoring

    [one or more errors occurred while gathering container data for pod node-exporter-bxzkw:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/node-exporter?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/node-exporter?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/init-textfile?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/init-textfile?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod prometheus-k8s-1:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/prometheus?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/prometheus?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/thanos-sidecar?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/thanos-sidecar?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-web?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-web?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-thanos?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-thanos?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/init-config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/init-config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering customresourcedefinitions.apiextensions.k8s.io due to error: skipping gathering namespaces/openshift-cluster-node-tuning-operator due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-cluster-node-tuning-operator

    one or more errors occurred while gathering container data for pod tuned-wqv2c:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-cluster-node-tuning-operator/tuned-wqv2c/tuned?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-cluster-node-tuning-operator/tuned-wqv2c/tuned?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-kube-apiserver due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-kube-apiserver

    [one or more errors occurred while gathering container data for pod installer-10-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-10-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-10-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-12-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-12-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-12-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-13-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-13-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-13-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-14-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-14-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-14-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-apiserver-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-apiserver-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-syncer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-syncer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-regeneration-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-regeneration-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-insecure-readyz?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-insecure-readyz?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-check-endpoints?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-check-endpoints?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-10-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-10-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-10-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-11-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-11-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-11-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-12-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-12-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-12-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-13-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-13-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-13-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-14-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-14-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-14-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering mutatingwebhookconfigurations.admissionregistration.k8s.io due to error: skipping gathering namespaces/multicluster-engine due to error: one or more errors occurred while gathering pod-specific data for namespace: multicluster-engine

    one or more errors occurred while gathering container data for pod assisted-service-5bff7d6554-rppvk:

    [Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/assisted-service?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/assisted-service?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/postgres?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/postgres?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering validatingwebhookconfigurations.admissionregistration.k8s.io due to error: skipping gathering namespaces/openshift-multus due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-multus

    [one or more errors occurred while gathering container data for pod multus-additional-cni-plugins-j5txh:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/kube-multus-additional-cni-plugins?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/kube-multus-additional-cni-plugins?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/egress-router-binary-copy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/egress-router-binary-copy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/cni-plugins?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/cni-plugins?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/bond-cni-plugin?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/bond-cni-plugin?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/routeoverride-cni?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/routeoverride-cni?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni-bincopy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni-bincopy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod multus-c7dfk:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-c7dfk/kube-multus?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-c7dfk/kube-multus?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod network-metrics-daemon-gjbpn:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/network-metrics-daemon?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/network-metrics-daemon?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering validatingwebhookconfigurations.admissionregistration.k8s.io due to error: skipping gathering namespaces/openshift-storage due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-storage

    one or more errors occurred while gathering container data for pod vg-manager-ftczx:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-storage/vg-manager-ftczx/vg-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-storage/vg-manager-ftczx/vg-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-kube-controller-manager due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-kube-controller-manager

    [one or more errors occurred while gathering container data for pod installer-3-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-3-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-3-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-4-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-4-retry-1-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-retry-1-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-retry-1-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-controller-manager-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-controller-manager-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/cluster-policy-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/cluster-policy-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-cert-syncer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-cert-syncer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-recovery-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-recovery-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-kube-scheduler due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-kube-scheduler

    [one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-6-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-6-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-6-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod openshift-kube-scheduler-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-cert-syncer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-cert-syncer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-recovery-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-recovery-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/wait-for-host-port?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/wait-for-host-port?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-6-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/revision-pruner-6-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/revision-pruner-6-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-machine-config-operator due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-machine-config-operator

    [one or more errors occurred while gathering container data for pod kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/kube-rbac-proxy-crio?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/kube-rbac-proxy-crio?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod machine-config-daemon-2q9pp:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/machine-config-daemon?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/machine-config-daemon?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod machine-config-server-d2vvk:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-server-d2vvk/machine-config-server?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-server-d2vvk/machine-config-server?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-user-workload-monitoring due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-user-workload-monitoring

    [one or more errors occurred while gathering container data for pod prometheus-user-workload-0:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/prometheus?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/prometheus?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/thanos-sidecar?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/thanos-sidecar?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-federate?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-federate?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-thanos?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-thanos?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/init-config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/init-config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod thanos-ruler-user-workload-0:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/thanos-ruler?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/thanos-ruler?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-web?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-web?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-ovn-kubernetes due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-ovn-kubernetes

    [one or more errors occurred while gathering container data for pod ovnkube-control-plane-5cf568db98-6bwqn:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/ovnkube-cluster-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/ovnkube-cluster-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod ovnkube-node-rbwzq:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-acl-logging?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-acl-logging?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-node?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-node?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-ovn-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-ovn-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/northd?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/northd?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/nbdb?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/nbdb?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/sbdb?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/sbdb?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovnkube-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovnkube-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kubecfg-setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kubecfg-setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-network-diagnostics due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-network-diagnostics

    one or more errors occurred while gathering container data for pod network-check-target-75b4q:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-network-diagnostics/network-check-target-75b4q/network-check-target-container?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-diagnostics/network-check-target-75b4q/network-check-target-container?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-network-node-identity due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-network-node-identity

    one or more errors occurred while gathering container data for pod network-node-identity-dwc4x:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/webhook?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/webhook?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/approver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/approver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-network-operator due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-network-operator

    one or more errors occurred while gathering container data for pod iptables-alerter-zc9f2:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-network-operator/iptables-alerter-zc9f2/iptables-alerter?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-operator/iptables-alerter-zc9f2/iptables-alerter?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-apiserver due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-apiserver

    one or more errors occurred while gathering container data for pod apiserver-8d6594568-h4jmd:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver-check-endpoints?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver-check-endpoints?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/fix-audit-permissions?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/fix-audit-permissions?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering endpoints/host-etcd-2 due to error: endpoints "host-etcd-2" not found, skipping gathering namespaces/openshift-controller-manager due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-controller-manager

    one or more errors occurred while gathering container data for pod controller-manager-5d847b76d9-wl5x4:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-controller-manager/controller-manager-5d847b76d9-wl5x4/controller-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-controller-manager/controller-manager-5d847b76d9-wl5x4/controller-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-route-controller-manager due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-route-controller-manager

    one or more errors occurred while gathering container data for pod route-controller-manager-59759f8564-fzz6b:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-route-controller-manager/route-controller-manager-59759f8564-fzz6b/route-controller-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-route-controller-manager/route-controller-manager-59759f8564-fzz6b/route-controller-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering sharedconfigmaps.sharedresource.openshift.io due to error: the server doesn't have a resource type "sharedconfigmaps", skipping gathering sharedsecrets.sharedresource.openshift.io due to error: the server doesn't have a resource type "sharedsecrets"]
error: the server doesn't have a resource type "clusters"
Gathering data for ns/openshift-cluster-samples-operator...
Gathering data for ns/openshift-operator-lifecycle-manager...
Gathering data for ns/openshift-service-ca-operator...
Gathering data for ns/openshift-service-ca...
Gathering data for ns/openshift-cluster-csi-drivers...
Wrote inspect data to must-gather.
error: inspection completed with the errors occurred while gathering data:
    [skipping gathering namespaces/openshift-authentication due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-authentication

    one or more errors occurred while gathering container data for pod oauth-openshift-6d798f766c-qdfqm:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-authentication/oauth-openshift-6d798f766c-qdfqm/oauth-openshift?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-authentication/oauth-openshift-6d798f766c-qdfqm/oauth-openshift?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-oauth-apiserver due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-oauth-apiserver

    one or more errors occurred while gathering container data for pod apiserver-65676db74b-scpbf:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/oauth-apiserver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/oauth-apiserver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/fix-audit-permissions?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-oauth-apiserver/apiserver-65676db74b-scpbf/fix-audit-permissions?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-machine-api due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-machine-api

    one or more errors occurred while gathering container data for pod ironic-proxy-r2ssq:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-api/ironic-proxy-r2ssq/ironic-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-api/ironic-proxy-r2ssq/ironic-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-dns due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-dns

    [one or more errors occurred while gathering container data for pod dns-default-74tff:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/dns?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/dns?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/dns-default-74tff/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod node-resolver-v4hjb:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-dns/node-resolver-v4hjb/dns-node-resolver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-dns/node-resolver-v4hjb/dns-node-resolver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-etcd due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-etcd

    [one or more errors occurred while gathering container data for pod etcd-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod etcd-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcdctl?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-readyz?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-ensure-env-vars?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/etcd-hub-ctlplane-0.5g-deployment.lab/etcd-resources-copy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-7-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/installer-8-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-7-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-7-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-8-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-etcd/revision-pruner-8-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-image-registry due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-image-registry

    one or more errors occurred while gathering container data for pod node-ca-gnpnf:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-image-registry/node-ca-gnpnf/node-ca?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-image-registry/node-ca-gnpnf/node-ca?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-ingress-canary due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-ingress-canary

    one or more errors occurred while gathering container data for pod ingress-canary-w85b8:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-ingress-canary/ingress-canary-w85b8/serve-healthcheck-canary?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ingress-canary/ingress-canary-w85b8/serve-healthcheck-canary?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering secrets/support due to error: secrets "support" not found, skipping gathering customresourcedefinitions.apiextensions.k8s.io due to error: skipping gathering namespaces/openshift-monitoring due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-monitoring

    [one or more errors occurred while gathering container data for pod node-exporter-bxzkw:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/node-exporter?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/node-exporter?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/init-textfile?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/node-exporter-bxzkw/init-textfile?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod prometheus-k8s-1:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/prometheus?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/prometheus?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/thanos-sidecar?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/thanos-sidecar?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-web?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-web?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-thanos?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/kube-rbac-proxy-thanos?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/init-config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-monitoring/prometheus-k8s-1/init-config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering customresourcedefinitions.apiextensions.k8s.io due to error: skipping gathering namespaces/openshift-cluster-node-tuning-operator due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-cluster-node-tuning-operator

    one or more errors occurred while gathering container data for pod tuned-wqv2c:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-cluster-node-tuning-operator/tuned-wqv2c/tuned?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-cluster-node-tuning-operator/tuned-wqv2c/tuned?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-kube-apiserver due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-kube-apiserver

    [one or more errors occurred while gathering container data for pod installer-10-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-10-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-10-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-12-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-12-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-12-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-13-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-13-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-13-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-14-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-14-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/installer-14-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-apiserver-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-apiserver-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-syncer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-syncer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-regeneration-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-cert-regeneration-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-insecure-readyz?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-insecure-readyz?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-check-endpoints?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/kube-apiserver-check-endpoints?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/kube-apiserver-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-10-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-10-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-10-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-11-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-11-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-11-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-12-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-12-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-12-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-13-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-13-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-13-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-14-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-14-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-apiserver/revision-pruner-14-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering mutatingwebhookconfigurations.admissionregistration.k8s.io due to error: skipping gathering namespaces/multicluster-engine due to error: one or more errors occurred while gathering pod-specific data for namespace: multicluster-engine

    one or more errors occurred while gathering container data for pod assisted-service-5bff7d6554-rppvk:

    [Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/assisted-service?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/assisted-service?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/postgres?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/multicluster-engine/assisted-service-5bff7d6554-rppvk/postgres?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering validatingwebhookconfigurations.admissionregistration.k8s.io due to error: skipping gathering namespaces/openshift-multus due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-multus

    [one or more errors occurred while gathering container data for pod multus-additional-cni-plugins-j5txh:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/kube-multus-additional-cni-plugins?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/kube-multus-additional-cni-plugins?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/egress-router-binary-copy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/egress-router-binary-copy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/cni-plugins?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/cni-plugins?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/bond-cni-plugin?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/bond-cni-plugin?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/routeoverride-cni?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/routeoverride-cni?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni-bincopy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni-bincopy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-additional-cni-plugins-j5txh/whereabouts-cni?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod multus-c7dfk:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-c7dfk/kube-multus?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/multus-c7dfk/kube-multus?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod network-metrics-daemon-gjbpn:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/network-metrics-daemon?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/network-metrics-daemon?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-multus/network-metrics-daemon-gjbpn/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering validatingwebhookconfigurations.admissionregistration.k8s.io due to error: skipping gathering namespaces/openshift-storage due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-storage

    one or more errors occurred while gathering container data for pod vg-manager-ftczx:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-storage/vg-manager-ftczx/vg-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-storage/vg-manager-ftczx/vg-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-kube-controller-manager due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-kube-controller-manager

    [one or more errors occurred while gathering container data for pod installer-3-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-3-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-3-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-4-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-4-retry-1-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-retry-1-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-4-retry-1-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-controller-manager-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod kube-controller-manager-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/cluster-policy-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/cluster-policy-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-cert-syncer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-cert-syncer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-recovery-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-controller-manager/kube-controller-manager-hub-ctlplane-0.5g-deployment.lab/kube-controller-manager-recovery-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-kube-scheduler due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-kube-scheduler

    [one or more errors occurred while gathering container data for pod installer-5-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-5-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod installer-6-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-6-hub-ctlplane-0.5g-deployment.lab/installer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/installer-6-hub-ctlplane-0.5g-deployment.lab/installer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod openshift-kube-scheduler-guard-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-guard-hub-ctlplane-0.5g-deployment.lab/guard?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-guard-hub-ctlplane-0.5g-deployment.lab/guard?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-cert-syncer?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-cert-syncer?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-recovery-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/kube-scheduler-recovery-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/wait-for-host-port?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/openshift-kube-scheduler-hub-ctlplane-0.5g-deployment.lab/wait-for-host-port?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod revision-pruner-6-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/revision-pruner-6-hub-ctlplane-0.5g-deployment.lab/pruner?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-kube-scheduler/revision-pruner-6-hub-ctlplane-0.5g-deployment.lab/pruner?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-machine-config-operator due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-machine-config-operator

    [one or more errors occurred while gathering container data for pod kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/kube-rbac-proxy-crio?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/kube-rbac-proxy-crio?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/kube-rbac-proxy-crio-hub-ctlplane-0.5g-deployment.lab/setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod machine-config-daemon-2q9pp:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/machine-config-daemon?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/machine-config-daemon?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-daemon-2q9pp/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod machine-config-server-d2vvk:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-server-d2vvk/machine-config-server?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-machine-config-operator/machine-config-server-d2vvk/machine-config-server?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-user-workload-monitoring due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-user-workload-monitoring

    [one or more errors occurred while gathering container data for pod prometheus-user-workload-0:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/prometheus?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/prometheus?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/thanos-sidecar?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/thanos-sidecar?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-federate?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-federate?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-thanos?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/kube-rbac-proxy-thanos?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/init-config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/prometheus-user-workload-0/init-config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod thanos-ruler-user-workload-0:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/thanos-ruler?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/thanos-ruler?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/config-reloader?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/config-reloader?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-web?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-web?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-user-workload-monitoring/thanos-ruler-user-workload-0/kube-rbac-proxy-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-ovn-kubernetes due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-ovn-kubernetes

    [one or more errors occurred while gathering container data for pod ovnkube-control-plane-5cf568db98-6bwqn:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/kube-rbac-proxy?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/kube-rbac-proxy?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/ovnkube-cluster-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-control-plane-5cf568db98-6bwqn/ovnkube-cluster-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], one or more errors occurred while gathering container data for pod ovnkube-node-rbwzq:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-acl-logging?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovn-acl-logging?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-node?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-node?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-ovn-metrics?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kube-rbac-proxy-ovn-metrics?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/northd?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/northd?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/nbdb?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/nbdb?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/sbdb?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/sbdb?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovnkube-controller?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/ovnkube-controller?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kubecfg-setup?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-ovn-kubernetes/ovnkube-node-rbwzq/kubecfg-setup?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host]], skipping gathering namespaces/openshift-network-diagnostics due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-network-diagnostics

    one or more errors occurred while gathering container data for pod network-check-target-75b4q:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-network-diagnostics/network-check-target-75b4q/network-check-target-container?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-diagnostics/network-check-target-75b4q/network-check-target-container?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-network-node-identity due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-network-node-identity

    one or more errors occurred while gathering container data for pod network-node-identity-dwc4x:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/webhook?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/webhook?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/approver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-node-identity/network-node-identity-dwc4x/approver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-network-operator due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-network-operator

    one or more errors occurred while gathering container data for pod iptables-alerter-zc9f2:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-network-operator/iptables-alerter-zc9f2/iptables-alerter?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-network-operator/iptables-alerter-zc9f2/iptables-alerter?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-apiserver due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-apiserver

    one or more errors occurred while gathering container data for pod apiserver-8d6594568-h4jmd:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver-check-endpoints?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/openshift-apiserver-check-endpoints?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/fix-audit-permissions?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-apiserver/apiserver-8d6594568-h4jmd/fix-audit-permissions?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering endpoints/host-etcd-2 due to error: endpoints "host-etcd-2" not found, skipping gathering namespaces/openshift-controller-manager due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-controller-manager

    one or more errors occurred while gathering container data for pod controller-manager-5d847b76d9-wl5x4:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-controller-manager/controller-manager-5d847b76d9-wl5x4/controller-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-controller-manager/controller-manager-5d847b76d9-wl5x4/controller-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering namespaces/openshift-route-controller-manager due to error: one or more errors occurred while gathering pod-specific data for namespace: openshift-route-controller-manager

    one or more errors occurred while gathering container data for pod route-controller-manager-59759f8564-fzz6b:

    [Get "https://172.16.30.20:10250/containerLogs/openshift-route-controller-manager/route-controller-manager-59759f8564-fzz6b/route-controller-manager?previous=true&timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, Get "https://172.16.30.20:10250/containerLogs/openshift-route-controller-manager/route-controller-manager-59759f8564-fzz6b/route-controller-manager?timestamps=true": dial tcp 172.16.30.20:10250: connect: no route to host, error trying to reach service: dial tcp 172.16.30.20:10250: connect: no route to host], skipping gathering sharedconfigmaps.sharedresource.openshift.io due to error: the server doesn't have a resource type "sharedconfigmaps", skipping gathering sharedsecrets.sharedresource.openshift.io due to error: the server doesn't have a resource type "sharedsecrets"]
error: the server doesn't have a resource type "clusters"

